{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82deb8d4",
   "metadata": {},
   "source": [
    "# Exercise 4: Seismic Hazard Assessment for Antananarivo, Madagascar\n",
    "\n",
    "This notebook demonstrates a workflow for probabilistic seismic hazard analysis (PSHA) at the city of Antananarivo, Madagascar. The main steps include:\n",
    "\n",
    "- **Data Acquisition:** Downloading and processing earthquake catalog data for the region using ObsPy and USGS FDSN web services.\n",
    "- **Geospatial Analysis:** Loading Madagascar's administrative boundaries and visualizing earthquake epicenters and city location using GeoPandas and Matplotlib.\n",
    "- **Catalog Processing:** Filtering the earthquake catalog for completeness, extracting relevant event parameters (magnitude, location, depth, time), and preparing data for statistical analysis.\n",
    "- **Gutenbergâ€“Richter Law Fitting:** Estimating the frequency-magnitude distribution parameters (`a` and `b`) to model the annual rate of earthquakes above a given magnitude.\n",
    "- **Distance Modeling:** Computing the distribution of earthquake distances to the city using the haversine formula and empirical binning.\n",
    "- **Ground Motion Prediction:** Defining a Ground Motion Prediction Equation (GMPE) to estimate peak ground acceleration (PGA) at the city for different earthquake scenarios.\n",
    "- **Hazard Curve Calculation:** Numerically integrating over magnitude and distance bins to compute the annual exceedance rate of ground motions (hazard curve).\n",
    "- **Return Period Analysis:** Interpolating the hazard curve to estimate the PGA corresponding to a 475-year return period (10% probability of exceedance in 50 years).\n",
    "\n",
    "Throughout the notebook, code cells are used for data processing, modeling, and visualization, while markdown cells provide documentation and explanations for each step. This workflow can be adapted for other regions and cities by modifying the input parameters and data sources.\n",
    "\n",
    "The following code cell ensures that all required Python packages for seismic hazard analysis are installed and available in the notebook environment. It checks for each package, installs any missing ones using `pip`, and imports them for use in subsequent cells. This step helps maintain reproducibility and prevents runtime errors due to missing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b46550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Install dependencies if missing\n",
    "import sys, subprocess, importlib\n",
    "\n",
    "def ensure(pkg, import_name=None):\n",
    "    name = import_name or pkg\n",
    "    try:\n",
    "        importlib.import_module(name)\n",
    "        print(f\"[ok] {pkg} already installed\")\n",
    "    except Exception:\n",
    "        print(f\"[info] Installing {pkg} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "        importlib.import_module(name)\n",
    "        print(f\"[ok] {pkg} installed\")\n",
    "\n",
    "\n",
    "pkgs = [\"os\", \"re\", \"requests\", \"zipfile\", \"geopandas\",\n",
    "        \"matplotlib\", \"shapely\", \"cartopy\", \"obspy\", \n",
    "        \"folium\", \"osmnx\", \"numpy\", \"pandas\"]\n",
    "\n",
    "for pkg in pkgs:\n",
    "    ensure(pkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65818f8",
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "\n",
    "In the next cell, we will import the required packages and define the parameters and constants needed for the exercise. We will also define functions that will be used later in the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports and constants\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import radians, sin, cos, asin, sqrt, log10, log, exp\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "import geopandas as gpd\n",
    "import requests, zipfile, io\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Constants\n",
    "R_EARTH_KM = 6371.0  # Earth radius in kilometers\n",
    "\n",
    "# Functions for PGA and MMI calculations\n",
    "def pga_joyner_boore_1981(M, E):\n",
    "    \"\"\"\n",
    "    Joyner & Boore (1981) attenuation equation.\n",
    "    PGA = 10^(0.249*M - log10(D) - 0.00255*D - 1.02)\n",
    "    D = sqrt(E^2 + 7.3^2)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    M : float\n",
    "        Magnitude\n",
    "    E : float\n",
    "        Epicentral distance (km)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    PGA : float\n",
    "        Peak ground acceleration (in g)\n",
    "    \"\"\"\n",
    "    D = np.sqrt(E**2 + 7.3**2)\n",
    "    log10_pga = 0.249*M - np.log10(D) - 0.00255*D - 1.02\n",
    "    PGA = 10**log10_pga\n",
    "    return PGA\n",
    "\n",
    "def mmi_from_pga(PGA):\n",
    "    \"\"\"\n",
    "    Convert PGA (in g) to MMI using Trifunac & Brady (1975).\n",
    "    MMI = (1/0.3) * (log10(PGA*980) - 0.014)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    PGA : float\n",
    "        Peak ground acceleration (in g)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    MMI : float\n",
    "        Modified Mercalli Intensity\n",
    "    \"\"\"\n",
    "    return (np.log10(PGA*980) - 0.014) / 0.3\n",
    "\n",
    "# Function to calculate haversine distance between two lat/lon points\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    km = R_EARTH_KM * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2404d58",
   "metadata": {},
   "source": [
    "# Setting Parameters\n",
    "\n",
    "In the next section, we define the parameters required to fetch the earthquake catalog for the area surrounding the center of Antananarivo city. We also specify additional parameters needed for subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Parameters (scenario definition, city location, bounding box)\n",
    "# Scenario earthquake definition\n",
    "SCENARIO_MAG = 7.0\n",
    "SCENARIO_DEPTH_KM = 10.0\n",
    "# Scenario epicenter (latitude, longitude). Here we use the city location for a worst-case scenario.\n",
    "SCENARIO_LAT = -18.9\n",
    "SCENARIO_LON = 47.5\n",
    "\n",
    "# City of interest\n",
    "CITY_NAME = \"Antananarivo\"\n",
    "CITY_LAT = -18.9\n",
    "CITY_LON = 47.5\n",
    "\n",
    "# Earthquake catalog search parameters\n",
    "MIN_LAT = -26.0\n",
    "MAX_LAT = -11.0\n",
    "MIN_LON = 42.0\n",
    "MAX_LON = 51.0\n",
    "START_DATE = UTCDateTime(1900, 1, 1)\n",
    "END_DATE = UTCDateTime.now()\n",
    "MIN_MAG = 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf1e035",
   "metadata": {},
   "source": [
    "# Earthquake Catalog Acquisition and Processing\n",
    "\n",
    "In this section, we fetch the earthquake catalog for Madagascar using the ObsPy FDSN client and USGS web services. The catalog is filtered to remove events with missing depth or magnitude information. For each event, we extract key parameters such as latitude, longitude, depth, magnitude, and origin time. We also compute the epicentral and hypocentral distances to Antananarivo using the haversine formula. The processed event data is stored in a GeoPandas GeoDataFrame for further analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee765f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Fetch earthquake catalog using ObsPy\n",
    "client = Client(\"USGS\")\n",
    "catalog = client.get_events(starttime=START_DATE, endtime=END_DATE,\n",
    "                            minlatitude=MIN_LAT, maxlatitude=MAX_LAT,\n",
    "                            minlongitude=MIN_LON, maxlongitude=MAX_LON,\n",
    "                            minmagnitude=MIN_MAG)\n",
    "print(f\"Fetched {catalog.count()} earthquake events from the catalog\")\n",
    "\n",
    "# Remove events with missing depth or magnitude\n",
    "catalog = [event for event in catalog if event.origins and event.magnitudes and\n",
    "           event.origins[0].depth is not None and event.magnitudes[0].mag is not None]\n",
    "print(f\"Number of events with depth and magnitude information: {len(catalog)}\")\n",
    "\n",
    "#%% Extract event data (latitude, longitude, depth, magnitude, distance, original_time)\n",
    "# into geopandas dataframe\n",
    "event_data = []\n",
    "for event in catalog:\n",
    "    origin = event.origins[0]\n",
    "    magnitude = event.magnitudes[0].mag if event.magnitudes else None\n",
    "    if origin and magnitude is not None:\n",
    "        event_data.append({\n",
    "            \"Latitude\": origin.latitude,\n",
    "            \"Longitude\": origin.longitude,\n",
    "            \"Depth_km\": origin.depth / 1000.0,  # convert to km\n",
    "            \"Magnitude\": magnitude,\n",
    "            \"Distance\": haversine(CITY_LAT, CITY_LON, origin.latitude, origin.longitude),\n",
    "            \"Hypo_dist\": sqrt(haversine(CITY_LAT, CITY_LON, origin.latitude,\n",
    "                                        origin.longitude)**2 + (origin.depth / 1000.0)**2),\n",
    "            \"original_time\": event.origins[0].time.datetime or event.preferred_origin().time.datetime\n",
    "        })\n",
    "\n",
    "events_gdf = gpd.GeoDataFrame(event_data, geometry=gpd.points_from_xy(\n",
    "    [d[\"Longitude\"] for d in event_data],\n",
    "    [d[\"Latitude\"] for d in event_data]\n",
    "))\n",
    "events_gdf['Year'] = pd.DatetimeIndex([d[\"original_time\"] for d in event_data]).year\n",
    "events_gdf['Month'] = pd.DatetimeIndex([d[\"original_time\"] for d in event_data]).month\n",
    "events_gdf['Day'] = pd.DatetimeIndex([d[\"original_time\"] for d in event_data]).day\n",
    "events_gdf['Date'] = pd.to_datetime(events_gdf[['Year', 'Month', 'Day']])\n",
    "events_gdf = events_gdf.drop(columns=['Month', 'Day'])\n",
    "events_gdf.reset_index(drop=True, inplace=True)\n",
    "print(f\"Prepared GeoDataFrame with {len(events_gdf)} events\")\n",
    "quakes = events_gdf.copy()\n",
    "\n",
    "print(events_gdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a85dca8",
   "metadata": {},
   "source": [
    "# Madagascar Boundary and Earthquake Epicenter Visualization\n",
    "\n",
    "This cell downloads and loads the administrative boundary shapefile for Madagascar, extracts the relevant provinces, and visualizes them using GeoPandas and Matplotlib. The city of Antananarivo is marked with a red star, and earthquake epicenters from the processed catalog are plotted as blue markers. This map provides spatial context for the seismic hazard analysis, showing the distribution of historical earthquakes relative to the city and administrative regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1bf663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Download and load Madagascar boundary and admin provinces shapefile\n",
    "import os\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "\n",
    "URL = \"https://naturalearth.s3.amazonaws.com/10m_cultural/ne_10m_admin_1_states_provinces.zip\"\n",
    "OUT_DIR = \"ne_admin1_10m\"\n",
    "ZIP_NAME = os.path.basename(URL)\n",
    "ZIP_PATH = os.path.join(OUT_DIR, ZIP_NAME)\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Check if already downloaded\n",
    "if os.path.exists(ZIP_PATH):\n",
    "    print(f\"Shapefile zip already downloaded: {ZIP_PATH}\")\n",
    "else:\n",
    "    # Download with streaming to avoid loading whole file in memory\n",
    "    with requests.get(URL, stream=True, timeout=60) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(ZIP_PATH, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024 * 64):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "# Extract all contents\n",
    "with ZipFile(ZIP_PATH) as zf:\n",
    "    zf.extractall(OUT_DIR)\n",
    "\n",
    "print(f\"Downloaded: {ZIP_PATH}\")\n",
    "print(f\"Extracted to: {OUT_DIR}\")\n",
    "\n",
    "#%% Load the shapefile using geopandas\n",
    "shapefile_path = os.path.join(OUT_DIR, \"ne_10m_admin_1_states_provinces.shp\")\n",
    "madagascar_boundary = gpd.read_file(shapefile_path)\n",
    "madagascar_boundary = madagascar_boundary[madagascar_boundary['admin'] == 'Madagascar']\n",
    "print(f\"Loaded Madagascar boundary with {len(madagascar_boundary)} provinces\")\n",
    "\n",
    "\n",
    "# Plot and add the earthquake events to verify\n",
    "madagascar_boundary.plot(figsize=(10, 10), facecolor='none', edgecolor='black')\n",
    "plt.scatter(CITY_LON, CITY_LAT, marker='*', color='red', s=100)\n",
    "plt.scatter(events_gdf['Longitude'], events_gdf['Latitude'], marker=(5, 2), color='blue', \n",
    "            s=10, alpha=0.5, label='Earthquakes')\n",
    "plt.text(CITY_LON, CITY_LAT+0.2, CITY_NAME, fontsize=12, ha='center', va='bottom', color='red')\n",
    "plt.title(\"Madagascar Boundary with City Location\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f6336c",
   "metadata": {},
   "source": [
    "# Earthquake Catalog Filtering and Magnitude-Frequency Analysis\n",
    "\n",
    "This cell creates a simplified DataFrame (`quakes`) containing the key parameters for each earthquake: magnitude, year, latitude, and longitude. It then visualizes the frequency distribution of earthquake magnitudes in the catalog using a histogram. This plot helps assess the completeness of the catalog and provides insight into the observed magnitude-frequency relationship, which is essential for seismic hazard modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a289462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Make a DataFrame `quakes` containing columns for \n",
    "# 'Magnitude', 'Year', 'Latitude', and 'Longitude' of each earthquake.\n",
    "quakes = events_gdf[['Magnitude', 'Year', 'Latitude', 'Longitude']]\n",
    "print(quakes.head())\n",
    "\n",
    "#%% Plot the catalog events to check the completeness of the catalog\n",
    "# Plot magnitude vs frequency\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(quakes['Magnitude'].values, bins=10, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Earthquake Magnitude vs Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5802f4",
   "metadata": {},
   "source": [
    "# Gutenbergâ€“Richter Law Fitting and Seismicity Rate Estimation\n",
    "\n",
    "This cell fits the Gutenbergâ€“Richter recurrence law to the earthquake catalog for Madagascar. The catalog is filtered for completeness above a minimum magnitude threshold (`M_min`). For each magnitude, the cumulative number of events per year is calculated, and a linear regression is performed on the log-transformed rates to estimate the Gutenbergâ€“Richter parameters (`a` and `b`). The resulting model describes the expected annual frequency of earthquakes above a given magnitude, which is a key input for probabilistic seismic hazard analysis. The observed data and fitted relation are visualized to assess the fit quality and catalog completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Gutenbergâ€“Richter fitting\n",
    "# Fit the Gutenbergâ€“Richter recurrence law (frequencyâ€“magnitude distribution) to the earthquake catalog.\n",
    "# Steps:\n",
    "# 1. Filter the catalog for completeness (e.g., use a minimum magnitude M_min).\n",
    "# 2. Compute the cumulative number of events N(M >= m) for each magnitude m in the catalog.\n",
    "# 3. Fit a linear relation log10(N) = a - b * m using least squares to estimate a and b.\n",
    "# 4. Calculate the total annual occurrence rate of earthquakes above M_min.\n",
    "\n",
    "# Set a completeness threshold for magnitude (adjust as needed based on data completeness).\n",
    "M_min = 4.0\n",
    "catalog = quakes[quakes['Magnitude'] >= M_min].copy()\n",
    "\n",
    "# Calculate the timespan of the catalog in years for rate normalization.\n",
    "years = catalog['Year'].max() - catalog['Year'].min() + 1\n",
    "\n",
    "# Sort magnitudes and compute cumulative counts for N(M >= m).\n",
    "mags = np.sort(catalog['Magnitude'].values)\n",
    "unique_mags = np.unique(mags)\n",
    "\n",
    "# Calculate cumulative number of events for each unique magnitude threshold.\n",
    "cum_counts = np.array([np.sum(mags >= m) for m in unique_mags])\n",
    "\n",
    "# Convert counts to annual rates:\n",
    "annual_cum_rates = cum_counts / years\n",
    "\n",
    "# Perform a linear fit to log10 of cumulative rates vs magnitude.\n",
    "logN = np.log10(annual_cum_rates)\n",
    "slope, intercept = np.polyfit(unique_mags, logN, 1)\n",
    "\n",
    "# The fitted line is log10(N) â‰ˆ intercept + slope * M.\n",
    "# For Gutenberg-Richter form log10(N) = a - b*M, we have:\n",
    "b_value = -slope\n",
    "a_value = intercept  # intercept corresponds to log10 of annual N at M = 0 (extrapolated).\n",
    "print(f\"Fitted Gutenbergâ€“Richter parameters: a = {a_value:.2f}, b = {b_value:.2f}\")\n",
    "\n",
    "# Plot the fitted Gutenbergâ€“Richter relation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(unique_mags, annual_cum_rates, color='blue', label='Observed Data')\n",
    "plt.plot(unique_mags, 10**(intercept + slope * unique_mags), color='red', label='Fitted Model')\n",
    "plt.xscale('linear')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Cumulative Annual Rate (events/year)')\n",
    "plt.title('Gutenbergâ€“Richter Relation')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d34a6",
   "metadata": {},
   "source": [
    "# Magnitude and Distance Binning for Hazard Calculation\n",
    "\n",
    "This cell prepares magnitude and distance bins required for the numerical integration of the seismic hazard curve. Magnitude bins are defined from the completeness threshold (`M_min`) to the maximum observed magnitude, with a specified bin width (`dM`). Distance bins and their empirical probabilities are taken from the previously computed distribution. The annual occurrence rate for each magnitude bin is calculated using the fitted Gutenbergâ€“Richter law. A bar chart visualizes the annual rates per magnitude bin, providing insight into the frequency of different earthquake sizes in the region. These binned rates and probabilities are essential inputs for the subsequent hazard integration step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Distance modeling to the city\n",
    "# Compute the distance from each earthquake epicenter to the city (Antananarivo).\n",
    "# We will use the haversine formula for great-circle distance between two lat/lon points.\n",
    "# Compute distances and add as a new column in the catalog DataFrame.\n",
    "city_lat = CITY_LAT\n",
    "city_lon = CITY_LON\n",
    "catalog['Distance_km'] = catalog.apply(lambda row: haversine(city_lat, city_lon, \n",
    "                                                            row['Latitude'], row['Longitude']), axis=1)\n",
    "\n",
    "# Derive an empirical distance distribution from the catalog (for use in hazard integration).\n",
    "# For simplicity, bin the distances and compute the proportion of events in each bin.\n",
    "max_dist = catalog['Distance_km'].max()\n",
    "# Define distance bins (adjust bin size for region as needed, e.g., 50 km bins here):\n",
    "bin_width = 50.0  # km\n",
    "dist_bins = np.arange(0, max_dist + bin_width, bin_width)\n",
    "hist_counts, bin_edges = np.histogram(catalog['Distance_km'], bins=dist_bins)\n",
    "distance_prob = hist_counts / hist_counts.sum()  # probability of an event falling in each distance bin\n",
    "# Define representative distance for each bin (bin midpoints):\n",
    "dist_bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# Plot the empirical distance distribution as a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(dist_bin_centers, distance_prob, width=bin_width, color='blue', \n",
    "        alpha=0.7, label='Empirical Distribution')\n",
    "plt.xlabel('Distance (km)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Empirical Distance Distribution of Earthquakes')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f285b2e",
   "metadata": {},
   "source": [
    "# Hazard Curve Calculation and Annual Exceedance Rate\n",
    "\n",
    "This cell performs the core probabilistic seismic hazard analysis (PSHA) integration. Using the previously defined magnitude and distance bins, Gutenbergâ€“Richter rates, and ground motion prediction equation (GMPE), it computes the annual exceedance rate for a range of peak ground acceleration (PGA) levels at Antananarivo. The calculation applies the total probability theorem, summing over all magnitude and distance combinations weighted by their occurrence rates and empirical probabilities. The resulting hazard curve shows the expected frequency of exceeding different PGA levels, providing a quantitative measure of seismic risk for the city.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% GMPE definition and probability model\n",
    "# Define the Ground Motion Prediction Equation (GMPE) and the probability model for ground motion.\n",
    "# We use an example GMPE (e.g., from Fukushima & Tanaka 1990, as cited in RADIUS methodology for rock site conditions).\n",
    "# Formula (for PGA in rock): PGA = 10^(0.249*M - log10(D) - 0.00255*D - 1.02), where \n",
    "# D = sqrt(distance^2 + 7.3^2) (distance in km, includes a near-source saturation term 7.3 km).\n",
    "# This yields PGA in units of g (approximate). We assume rock site (no site amplification).\n",
    "def gmpe_pga(magnitude, distance_km):\n",
    "    # Effective distance with near-source term\n",
    "    D = np.sqrt(distance_km**2 + 7.3**2)\n",
    "    # Compute log10(PGA) based on magnitude and distance\n",
    "    log10_pga = 0.249 * magnitude - np.log10(D) - 0.00255 * D - 1.02\n",
    "    return 10**(log10_pga)\n",
    "\n",
    "# Define the standard deviation of log10(PGA) for the GMPE (aleatory uncertainty).\n",
    "sigma_log10 = 0.22  # e.g., sigma(log10 PGA) â‰ˆ 0.22 for rock (from Joyner & Boore 1981) [oai_citation:0â€¡file-8jqdxfnb1b5dxt3fpqbkme](file://file-8jQDxfnb1b5Dxt3FpqbKme#:~:text=ln%20PGA%20%3D%20%E2%88%921,S) [oai_citation:1â€¡file-8jqdxfnb1b5dxt3fpqbkme](file://file-8jQDxfnb1b5Dxt3FpqbKme#:~:text=PGA%3D10%5E%280.249%2AM)\n",
    "\n",
    "# Probability that ground motion (PGA) exceeds a threshold x given magnitude m and distance d.\n",
    "def prob_exceedance(magnitude, distance_km, pga_threshold):\n",
    "    median_pga = gmpe_pga(magnitude, distance_km)  # median PGA (g) from GMPE\n",
    "    # Calculate standard normal variate for log10(PGA) distribution\n",
    "    z = (np.log10(pga_threshold) - np.log10(median_pga)) / sigma_log10\n",
    "    # Return the exceedance probability (1 - CDF)\n",
    "    return 1 - norm.cdf(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f6404",
   "metadata": {},
   "source": [
    "# Numerical Integration of the Seismic Hazard Curve\n",
    "\n",
    "This cell implements the total probability theorem to numerically integrate the seismic hazard curve for Antananarivo. Using the previously defined magnitude and distance bins, annual occurrence rates, empirical distance probabilities, and the ground motion prediction equation (GMPE), it calculates the annual exceedance rate for a range of peak ground acceleration (PGA) levels. The resulting hazard curve quantifies the likelihood of experiencing different levels of ground shaking at the city, providing a key metric for seismic risk assessment and engineering design. The curve is visualized on a log-log scale to highlight both frequent and rare events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Magnitude and distance binning\n",
    "# Prepare magnitude and distance bins for the numerical integration in hazard calculation.\n",
    "# Define magnitude bins from M_min to a maximum magnitude (M_max). \n",
    "M_max = max(M_min, catalog['Magnitude'].max())\n",
    "# Extend M_max slightly (e.g., to next 0.5) to account for the possibility of larger events.\n",
    "M_max = np.ceil(M_max * 2) / 2.0\n",
    "dM = 0.1  # magnitude bin width\n",
    "mag_bins = np.arange(M_min, M_max + dM, dM)\n",
    "mag_bin_centers = 0.5 * (mag_bins[:-1] + mag_bins[1:])\n",
    "\n",
    "# Use the distance bins and probabilities from the empirical distribution:\n",
    "distance_bins = dist_bin_centers  # representative distances for each bin\n",
    "distance_probs = distance_prob    # probability of an event in each distance bin\n",
    "\n",
    "# Compute the annual occurrence rate for each magnitude bin using the Gutenbergâ€“Richter law.\n",
    "# N(M >= m) = 10^(a - b*m). Rate in bin [m_i, m_{i+1}) = N(>= m_i) - N(>= m_{i+1}).\n",
    "N_gt = 10**(a_value - b_value * mag_bins)  # cumulative annual rates at bin edges\n",
    "annual_rate_bins = N_gt[:-1] - N_gt[1:]    # annual rate in each mag bin\n",
    "\n",
    "# Plot the annual rates per magnitude bin\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(mag_bin_centers, annual_rate_bins, width=dM, color='blue', alpha=0.7)\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('Annual Rate (events/year)')\n",
    "plt.title('Annual Occurrence Rate per Magnitude Bin')\n",
    "plt.grid()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6345e6",
   "metadata": {},
   "source": [
    "# Seismic Hazard Curve Integration and Interpretation\n",
    "\n",
    "This cell performs the numerical integration of the seismic hazard curve for Antananarivo using the total probability theorem. For each ground motion level (PGA), it sums the contributions from all magnitude and distance bins, weighted by their annual occurrence rates and empirical probabilities. The resulting hazard curve quantifies the expected frequency of exceeding different PGA levels at the city. This analysis provides a key metric for seismic risk assessment, supporting engineering design and disaster planning. The hazard curve is visualized to illustrate the relationship between ground shaking intensity and exceedance probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daac10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Hazard integration loop (compute annual exceedance rate)\n",
    "# Compute the annual exceedance rate for a range of PGA levels using the total probability theorem.\n",
    "# Î»_exceed(X) = âˆ‘_m âˆ‘_r [ Î»_m * P(r) * P(PGA > X | m, r) ],\n",
    "# where Î»_m is rate of events in mag bin m, P(r) is probability of an event at distance r, and the last term is conditional exceedance probability.\n",
    "\n",
    "# Define an array of PGA levels (in g) for the hazard curve.\n",
    "pga_min = 1e-3  # 0.001g\n",
    "pga_max = 1.0   # 1.0g (adjust if necessary)\n",
    "pga_levels = np.logspace(np.log10(pga_min), np.log10(pga_max), 100)  # log-spaced for resolution\n",
    "\n",
    "exceedance_rates = []  # will store computed annual exceedance frequencies for each PGA level\n",
    "for x in pga_levels:\n",
    "    total_rate = 0.0\n",
    "    # Sum contributions from each magnitude and distance bin\n",
    "    for i, m in enumerate(mag_bin_centers):\n",
    "        lam_m = annual_rate_bins[i]            # annual rate of events in this magnitude bin\n",
    "        for j, r in enumerate(distance_bins):\n",
    "            p_r = distance_probs[j]            # probability of an event occurring at distance ~r\n",
    "            p_exc = prob_exceedance(m, r, x)   # probability that PGA > x given an event of mag m at distance r\n",
    "            total_rate += lam_m * p_r * p_exc\n",
    "    exceedance_rates.append(total_rate)\n",
    "exceedance_rates = np.array(exceedance_rates)\n",
    "\n",
    "# Plot the hazard curve (annual exceedance rate vs PGA)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pga_levels, exceedance_rates, color='blue', lw=2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('PGA (g)')\n",
    "plt.ylabel('Annual Exceedance Rate (events/year)')\n",
    "plt.title('Seismic Hazard Curve at Antananarivo')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c906a703",
   "metadata": {},
   "source": [
    "# Return Period Ground Motion Estimation\n",
    "\n",
    "This cell calculates the peak ground acceleration (PGA) at Antananarivo corresponding to a 475-year return period, which represents a 10% probability of exceedance in 50 yearsâ€”a standard metric in seismic hazard analysis for engineering design. The target annual exceedance rate is computed, and the hazard curve is interpolated to find the PGA value matching this rate. The result is visualized on the hazard curve plot, with the 475-year return period PGA highlighted for reference. This value is crucial for seismic risk mitigation and building code applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Compute PGA for 10% in 50 years (475-year return period)\n",
    "# 10% probability of exceedance in 50 years corresponds to an annual exceedance rate:\n",
    "target_exceedance_rate = -np.log(1 - 0.10) / 50.0  # ~0.002105 per year\n",
    "# Interpolate the hazard curve to find the PGA value corresponding to this target rate.\n",
    "pga_475 = None\n",
    "if (exceedance_rates[-1] <= target_exceedance_rate) and (exceedance_rates[0] >= target_exceedance_rate):\n",
    "    # Interpolate in log-log space for better accuracy (hazard curve is roughly log-linear in log-log scale).\n",
    "    # Taking logs:\n",
    "    log_target = np.log10(target_exceedance_rate)\n",
    "    # Avoid taking log10 of zero which produces -inf and runtime warnings.\n",
    "    # Clip zero (or non-positive) exceedance rates to a tiny positive value\n",
    "    # based on the smallest positive rate computed (or a safe floor) so\n",
    "    # interpolation in log-log space remains well-defined.\n",
    "    if np.any(exceedance_rates > 0):\n",
    "        min_pos = exceedance_rates[exceedance_rates > 0].min()\n",
    "        eps = min_pos * 1e-6\n",
    "    else:\n",
    "        # if all rates are zero (degenerate case), use a very small floor\n",
    "        eps = 1e-20\n",
    "    clipped_rates = np.clip(exceedance_rates, eps, None)\n",
    "    with np.errstate(divide='ignore'):\n",
    "        log_rates = np.log10(clipped_rates)\n",
    "    log_pga = np.log10(pga_levels)\n",
    "    # Perform linear interpolation to find log10(PGA) at log_target.\n",
    "    pga_475_log = np.interp(log_target, log_rates[::-1], log_pga[::-1])\n",
    "    pga_475 = 10**pga_475_log\n",
    "else:\n",
    "    # If target rate is outside the range of computed hazard curve:\n",
    "    if exceedance_rates[0] < target_exceedance_rate:\n",
    "        print(\"Warning: target exceedance rate is higher than the curve maximum.\")\n",
    "    if exceedance_rates[-1] > target_exceedance_rate:\n",
    "        print(\"Warning: target exceedance rate is lower than the curve minimum.\")\n",
    "# Report the 475-year return period PGA value\n",
    "if pga_475 is not None:\n",
    "    print(f\"PGA for 10% in 50 years (~475-year return period) is approximately {pga_475:.3f} g\")\n",
    "else:\n",
    "    print(\"PGA for 475-year return period could not be determined from the computed range.\")\n",
    "\n",
    "# Plot hazard curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.loglog(pga_levels, exceedance_rates, label='Hazard curve')\n",
    "# Mark the 10% in 50yr point if available\n",
    "if pga_475 is not None:\n",
    "    plt.scatter([pga_475], [target_exceedance_rate], color='red', zorder=5, label='10% in 50yr point')\n",
    "    plt.axhline(y=target_exceedance_rate, color='red', linestyle='--', linewidth=0.8)\n",
    "    plt.axvline(x=pga_475, color='red', linestyle='--', linewidth=0.8)\n",
    "plt.title('Seismic Hazard Curve for Antananarivo')\n",
    "plt.xlabel('PGA (g)')\n",
    "plt.ylabel('Annual Exceedance Rate')\n",
    "plt.legend()\n",
    "plt.grid(True, which='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b1b7d6",
   "metadata": {},
   "source": [
    "# Extra tasks:\n",
    "* Use the scenario earthquake definition in the third cell to calculate the deterministic seismic hazard curve at the center of Antananarivo city."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

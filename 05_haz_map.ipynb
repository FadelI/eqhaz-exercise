{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de511a37",
   "metadata": {},
   "source": [
    "## Exercise 5: Probabilistic Seismic Hazard Analysis (PSHA) for Lampahan Region\n",
    "\n",
    "This notebook demonstrates a workflow for estimating earthquake hazard at the building level using open data and reproducible Python tools. The main steps include:\n",
    "\n",
    "- **Defining the Area of Interest:**  \n",
    "    The Lampahan region is specified using a bounding box, and its geometry is visualized.\n",
    "\n",
    "- **Downloading Building Footprints:**  \n",
    "    Building polygons are retrieved from OpenStreetMap (OSM) and plotted on the map.\n",
    "\n",
    "- **Fetching Earthquake Catalog:**  \n",
    "    Earthquake events since 1980 are downloaded from the USGS using the ObsPy FDSN client, filtered by magnitude and spatial extent.\n",
    "\n",
    "- **Computing Distances:**  \n",
    "    Epicentral distances from each building centroid to each earthquake are calculated using the haversine formula.\n",
    "\n",
    "- **Ground Motion Prediction:**  \n",
    "    The Atkinson & Boore (2003) ground motion model (GMPE) is used to estimate the median peak ground acceleration (PGA) at each building for each event.\n",
    "\n",
    "- **Hazard Curve Calculation:**  \n",
    "    For each building, the mean annual frequency of exceedance (MAFE) for several PGA levels is computed, assuming each event is a Poisson process.\n",
    "\n",
    "- **Probability Mapping:**  \n",
    "    The probability that PGA exceeds 0.2g in 50 years is mapped for all buildings, visualized both as a static plot and interactively with Folium.\n",
    "\n",
    "This exercise illustrates how open-source geospatial and seismological libraries can be combined for rapid, transparent hazard mapping at high spatial resolution. The workflow is modular and can be adapted for other regions, building datasets, or ground motion models.\n",
    "\n",
    "The following code cell ensures that all required Python packages for seismic hazard analysis are installed and available in the notebook environment. It checks for each package, installs any missing ones using `pip`, and imports them for use in subsequent cells. This step helps maintain reproducibility and prevents runtime errors due to missing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1264afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Install packages\n",
    "# 1) Install dependencies if missing\n",
    "import sys, subprocess, importlib\n",
    "\n",
    "def ensure(pkg, import_name=None):\n",
    "    name = import_name or pkg\n",
    "    try:\n",
    "        importlib.import_module(name)\n",
    "        print(f\"[ok] {pkg} already installed\")\n",
    "    except Exception:\n",
    "        print(f\"[info] Installing {pkg} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "        importlib.import_module(name)\n",
    "        print(f\"[ok] {pkg} installed\")\n",
    "\n",
    "\n",
    "pkgs = [\"os\", \"re\", \"requests\", \"zipfile\", \"geopandas\",\n",
    " \"matplotlib\", \"shapely\", \"cartopy\", \"obspy\", \"folium\"]\n",
    "\n",
    "for pkg in pkgs:\n",
    "    ensure(pkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bb3e98",
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "\n",
    "In the next cell, we will import the required packages and define the parameters and constants needed for the exercise. We will also define functions that will be used later in the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b848d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports and constants\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box, Point\n",
    "import osmnx as ox\n",
    "from math import radians, sin, cos, asin, sqrt, log10, log, exp\n",
    "from datetime import datetime\n",
    "import folium\n",
    "from folium import Choropleth, Circle, Marker\n",
    "from folium.plugins import MarkerCluster\n",
    "from branca.colormap import linear\n",
    "\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.core.utcdatetime import UTCDateTime\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "from math import log, sqrt\n",
    "from scipy.stats import norm\n",
    "\n",
    "ox.settings.log_console = False\n",
    "ox.settings.use_cache = True\n",
    "\n",
    "# Constants\n",
    "R_EARTH_KM = 6371.0  # Earth radius in kilometers\n",
    "\n",
    "# Prefer the `features` API (features_from_polygon) as shown in the Python-GIS guide.\n",
    "features_from_polygon = ox.features.features_from_polygon\n",
    "\n",
    "# Lampahan bounding box (degrees)\n",
    "min_lat, max_lat = 4.70, 4.80\n",
    "min_lon, max_lon = 96.70, 96.85\n",
    "\n",
    "# Create GeoDataFrame for the region (WGS84)\n",
    "region_poly = box(min_lon, min_lat, max_lon, max_lat)\n",
    "gdf_region = gpd.GeoDataFrame({\"name\": [\"Lampahan_box\"]}, geometry=[region_poly], crs=\"EPSG:4326\")\n",
    "\n",
    "ax = gdf_region.plot(facecolor=\"none\", edgecolor=\"red\", linewidth=2, figsize=(10,10))\n",
    "plt.title(\"Lampahan teaching region (hard-coded)\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e3470",
   "metadata": {},
   "source": [
    "# Downloading Building Footprints in the Aceh Lampahan Region\n",
    "\n",
    "In the next section, we will download the building footprints within the area of interest (AOI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5772474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Download building footprints from OSM\n",
    "tags = {\"building\": True}\n",
    "# Use the compatibility wrapper to fetch features (buildings) for the polygon AOI\n",
    "buildings = features_from_polygon(region_poly, tags)\n",
    "# Keep only polygons (some entries could be points/lines)\n",
    "buildings = buildings[buildings.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])].copy()\n",
    "buildings = buildings.to_crs(\"EPSG:4326\")\n",
    "\n",
    "print(f\"Downloaded {len(buildings)} building geometries from OSM.\")\n",
    "buildings.head(3)\n",
    "\n",
    "#%% plot buildings\n",
    "ax = gdf_region.plot(facecolor=\"none\", edgecolor=\"red\", linewidth=2, figsize=(10,10))\n",
    "buildings.plot(ax=ax, facecolor=\"lightgrey\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.title(\"Building footprints from OSM in Lampahan region\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f22e96",
   "metadata": {},
   "source": [
    "# Earthquake Catalog and Distance Calculation\n",
    "\n",
    "In the following cell, we download the earthquake catalog for the Lampahan region using the USGS FDSN client via ObsPy. The catalog includes events since 1980 with magnitude â‰¥ 5.0. For each earthquake, we extract the origin time, magnitude, latitude, longitude, and depth. We then compute the epicentral distance from each building centroid to each earthquake using the haversine formula. This distance matrix is essential for subsequent ground motion and hazard calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Download earthquake catalog from USGS\n",
    "# Using obspy's FDSN client interface\n",
    "client = Client(\"USGS\")\n",
    "t1 = UTCDateTime(\"1980-01-01\")\n",
    "t2 = UTCDateTime()\n",
    "minmag = 5.0\n",
    "\n",
    "# Expand the box a bit for sources just outside\n",
    "pad = 0.5\n",
    "cat = client.get_events(starttime=t1, endtime=t2, minmagnitude=minmag,\n",
    "                        minlatitude=min_lat - pad, maxlatitude=max_lat + pad,\n",
    "                        minlongitude=min_lon - pad, maxlongitude=max_lon + pad)\n",
    "\n",
    "print(f\"Fetched {len(cat)} earthquakes (USGS FDSN).\")\n",
    "\n",
    "\n",
    "# %%\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    km = R_EARTH_KM * c\n",
    "    return km\n",
    "\n",
    "rows = []\n",
    "for ev in cat:\n",
    "    o = ev.preferred_origin() or ev.origins[0]\n",
    "    m = ev.preferred_magnitude() or ev.magnitudes[0]\n",
    "    rows.append({\n",
    "        \"time\": o.time.datetime,\n",
    "        \"Mw\": float(m.mag),\n",
    "        \"lat\": float(o.latitude),\n",
    "        \"lon\": float(o.longitude),\n",
    "        \"depth_km\": float((o.depth or 0.0)/1000.0),\n",
    "        \"id\": ev.resource_id.id\n",
    "    })\n",
    "\n",
    "df_ev = pd.DataFrame(rows).sort_values(\"time\").reset_index(drop=True)\n",
    "df_ev.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea65f54",
   "metadata": {},
   "source": [
    "## Ground Motion and Hazard Curve Calculation\n",
    "\n",
    "In the next cell, we compute the seismic hazard for each building using the Atkinson & Boore (2003) ground motion model. For every building and earthquake event, the median peak ground acceleration (PGA) is estimated, and the probability of exceeding several PGA levels is calculated assuming lognormal variability. These probabilities are combined to produce a hazard curve for each building, and the probability of exceeding 0.2g in 50 years is mapped across the region. The results are visualized using a color-coded map to highlight spatial variations in seismic risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0636ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 4) Compact AB03 (2003) PGA (g) function for slab earthquakes\n",
    "# - Interface vs In-slab via depth threshold (50 km).\n",
    "# - Distance âˆ¼ epicentral distance (teaching simplification).\n",
    "# - We'll also define a helper to compute exceedance probability for a given PGA level assuming \n",
    "# a **lognormal** scatter with a single sigma in natural log (e.g., 0.6).\n",
    "#\n",
    "# **Reference**: Atkinson & Boore (2003) subduction GMPE (PGA). \n",
    "# (Coefficients and functional form as used earlier in this session.)\n",
    "# AB03 PGA coefficients (Table 1) for compact implementation\n",
    "AB03_PGA = {\n",
    "    \"interface\": dict(c1= 2.99100,  c2=0.03525, c3=0.00759,  c4=-0.00206,  c5=0.19, c6=0.24, c7=0.29),\n",
    "    \"inslab\":    dict(c1=-0.04713,  c2=0.60599, c3=0.01130,  c4=-0.000228, c5=0.19, c6=0.24, c7=0.29),\n",
    "}\n",
    "\n",
    "def g_slope(M, etype):\n",
    "    return 10.0**(1.2 - 0.18*M) if etype==\"interface\" else 10.0**(0.301 - 0.01*M)\n",
    "\n",
    "def D_of_M(M):  # km\n",
    "    return 0.00724 * (10.0 ** (0.507*M))\n",
    "\n",
    "def pga_ab03(Mw, depth_km, R_epi_km, site_class=\"B\"):\n",
    "    etype = \"interface\" if depth_km < 50.0 else \"inslab\"\n",
    "    M = min(Mw, 8.5 if etype==\"interface\" else 8.0)\n",
    "    h = min(depth_km, 100.0)\n",
    "    R = np.sqrt(R_epi_km**2 + D_of_M(M)**2)\n",
    "    C = AB03_PGA[etype]\n",
    "    SC = 1.0 if site_class.upper()==\"C\" else 0.0\n",
    "    SD = 1.0 if site_class.upper()==\"D\" else 0.0\n",
    "    SE = 1.0 if site_class.upper()==\"E\" else 0.0\n",
    "    log10Y = C[\"c1\"] + C[\"c2\"]*M + C[\"c3\"]*h + C[\"c4\"]*R + \\\n",
    "             g_slope(M, etype)*np.log10(R) + C[\"c5\"]*SC + C[\"c6\"]*SD + C[\"c7\"]*SE\n",
    "    Y_cms2 = 10.0**log10Y\n",
    "    return Y_cms2/981.0  # g\n",
    "\n",
    "\n",
    "def prob_exceed_given_event(pga_level_g, median_g, sigma_ln=0.6):\n",
    "    \"\"\"\n",
    "    P(IM > y | event) for a lognormal IM with ln-median=ln(median_g) and sigma_ln.\n",
    "    \"\"\"\n",
    "    mu = np.log(median_g)\n",
    "    z = (np.log(pga_level_g) - mu) / sigma_ln\n",
    "    return 1.0 - norm.cdf(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224e1980",
   "metadata": {},
   "source": [
    "# Get cell centroids and compute matric of epicentral distances.\n",
    "\n",
    "This cell prepares the building centroid points and calculates the epicentral distance from each building to every earthquake event in the catalog. The resulting distance matrix (`R_be`) is essential for estimating ground motion at each building location during each event, which is a key step in probabilistic seismic hazard analysis (PSHA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 5) Prepare building points and compute distances to each event\n",
    "# We take **centroids** of building polygons as representative building locations.\n",
    "# Building centroids\n",
    "build_pts = buildings.copy().to_crs(\"EPSG:32647\")  # UTM zone 47N\n",
    "build_pts[\"geometry\"] = build_pts.geometry.centroid\n",
    "build_pts = build_pts[[\"geometry\"]].reset_index(drop=True)\n",
    "build_pts = gpd.GeoDataFrame(build_pts, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Extract lat/lon arrays for speed\n",
    "b_lats = build_pts.geometry.y.values\n",
    "b_lons = build_pts.geometry.x.values\n",
    "\n",
    "# Event arrays\n",
    "ev_lats = df_ev[\"lat\"].values\n",
    "ev_lons = df_ev[\"lon\"].values\n",
    "ev_Mw   = df_ev[\"Mw\"].values\n",
    "ev_dep  = df_ev[\"depth_km\"].values\n",
    "\n",
    "# Compute matrix of epicentral distances (buildings x events)\n",
    "def epi_matrix_km(b_lats, b_lons, ev_lats, ev_lons):\n",
    "    B, E = len(b_lats), len(ev_lats)\n",
    "    R = np.zeros((B, E), dtype=float)\n",
    "    for i in range(B):\n",
    "        for j in range(E):\n",
    "            d_km = haversine(b_lats[i], b_lons[i], ev_lats[j], ev_lons[j])\n",
    "            R[i, j] = d_km\n",
    "    return R\n",
    "\n",
    "R_be = epi_matrix_km(b_lats, b_lons, ev_lats, ev_lons)\n",
    "R_be.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd968d0",
   "metadata": {},
   "source": [
    "# PSHA calculation\n",
    "\n",
    "This cell performs a probabilistic seismic hazard analysis (PSHA) for each building in the Lampahan region. It calculates the mean annual frequency of exceedance (MAFE) for several peak ground acceleration (PGA) levels using the earthquake catalog and the Atkinson & Boore (2003) ground motion model. The probability that each building will experience PGA greater than 0.2g in the next 50 years is computed and mapped. The results are visualized as a color-coded map, highlighting spatial variations in seismic risk across the building stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed318714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Toy example for PSHA at buildings\n",
    "# - Catalog spans from `t1` to `t2` â†’ duration **T_years**.\n",
    "# - Treat each event as a Poisson process with annual rate **1/T_years**.\n",
    "# - For a PGA level `y`, the **mean annual frequency of exceedance (MAFE)** at a building is:\n",
    "#   \\n\n",
    "#   `lambda(y) = sum_j [ (1/T) * P(IM > y | event j at that building) ]`\n",
    "#   \\n\n",
    "# - Convert to **probability in N years**: `P_N = 1 - exp(-lambda(y) * N)`.\n",
    "#\n",
    "# We'll compute a small **hazard curve** for each building and also a single map value:\n",
    "# **P( PGA > 0.2 g in 50 yrs )** at **Site Class = C** (changeable).\n",
    "T_years = (t2.datetime - t1.datetime).days / 365.25\n",
    "print(f\"Catalog duration T â‰ˆ {T_years:.1f} years\")\n",
    "\n",
    "# Settings\n",
    "site_class_default = \"C\"     # try \"B\", \"C\", \"D\", \"E\"\n",
    "sigma_ln_default   = 0.6     # pedagogical choice\n",
    "pga_levels_g       = np.array([0.05, 0.10, 0.20, 0.30])  # hazard curve levels\n",
    "N_years_for_map    = 50\n",
    "pga_map_level      = 0.20\n",
    "\n",
    "B, E = R_be.shape\n",
    "hazard_mafe = np.zeros((B, len(pga_levels_g)), dtype=float)\n",
    "\n",
    "# Precompute medians per building/event for speed\n",
    "median_g = np.zeros((B, E), dtype=float)\n",
    "for i in range(B):\n",
    "    for j in range(E):\n",
    "        median_g[i, j] = pga_ab03(ev_Mw[j], ev_dep[j], R_be[i, j], site_class=site_class_default)\n",
    "\n",
    "# Sum rates\n",
    "event_rate = 1.0 / T_years\n",
    "for k, y in enumerate(pga_levels_g):\n",
    "    # P(IM>y | event j) at building i\n",
    "    pij = 1.0 - norm.cdf((np.log(y) - np.log(median_g)) / sigma_ln_default)\n",
    "    # lambda_i(y) = sum_j rate * pij\n",
    "    hazard_mafe[:, k] = event_rate * np.sum(pij, axis=1)\n",
    "\n",
    "# Choose the mapping metric: P_N for y=0.2 g\n",
    "idx = list(pga_levels_g).index(pga_map_level)\n",
    "P50 = 1.0 - np.exp(-hazard_mafe[:, idx] * N_years_for_map)\n",
    "\n",
    "# Attach to buildings GeoDataFrame\n",
    "gdf_b = buildings.copy()\n",
    "gdf_b[\"PGA_level_g\"] = pga_map_level\n",
    "gdf_b[\"P_exceed_50yr\"] = P50\n",
    "gdf_b = gdf_b.set_geometry(gdf_b.geometry).to_crs(\"EPSG:4326\")\n",
    "\n",
    "gdf_b[[\"PGA_level_g\", \"P_exceed_50yr\"]].head()\n",
    "\n",
    "# Plot map\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "gdf_region.boundary.plot(ax=ax, color=\"black\", linewidth=1)\n",
    "# Color ramp caps to keep the map readable\n",
    "vals = gdf_b[\"P_exceed_50yr\"].clip(0, 0.5)   # cap at 50%\n",
    "gdf_b.plot(ax=ax, column=vals, cmap=\"viridis\", linewidth=0,\n",
    "           legend_kwds={\"label\": f\"P(PGA > {pga_map_level:.2f} g in {N_years_for_map} yrs)\",\n",
    "                        \"shrink\": 0.6}, vmax=1.0, vmin=0.0)\n",
    "plt.colorbar(ax.collections[0], ax=ax, fraction=0.03, pad=0.04)\n",
    "ax.set_title(f\"(Lampahan buildings â€” P(PGA > {pga_map_level:.2f}) g in {N_years_for_map} yrs), site={site_class_default})\")\n",
    "ax.set_xlabel(\"Longitude\"); ax.set_ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef1e2c",
   "metadata": {},
   "source": [
    "# Interactive Seismic Hazard Mapping with Folium\n",
    "\n",
    "This cell creates an interactive map of the Lampahan region using Folium, displaying the probability that each building will experience peak ground acceleration (PGA) greater than 0.2g in the next 50 years. Buildings are color-coded according to their exceedance probability, with a capped color scale for readability. Users can zoom and pan to explore spatial patterns of seismic risk at the building level. Tooltips provide detailed probability values for each building footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf658c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Plot on folium map (for interactive zoom/pan)\n",
    "# Center of the region\n",
    "center_lat = 0.5 * (min_lat + max_lat)\n",
    "center_lon = 0.5 * (min_lon + max_lon)  \n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=13, tiles=\"cartodbpositron\")\n",
    "# Color map\n",
    "colormap = linear.viridis.scale(0.0, 0.5)  # cap at 50%\n",
    "colormap.caption = f\"P(PGA > {pga_map_level:.2f} g in {N_years_for_map} yrs)\"\n",
    "colormap.add_to(m)\n",
    "# Add buildings\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "for _, row in gdf_b.iterrows():\n",
    "    p = row[\"P_exceed_50yr\"]\n",
    "    color = colormap(p) if p <= 0.5 else \"#800026\"  # dark red for >50%\n",
    "    folium.GeoJson(\n",
    "        row[\"geometry\"],\n",
    "        style_function=lambda feature, color=color: {\n",
    "            \"fillColor\": color,\n",
    "            \"color\": color,\n",
    "            \"weight\": 0,\n",
    "            \"fillOpacity\": 0.7,\n",
    "        },\n",
    "        tooltip=(f\"P(PGA > {pga_map_level:.2f} g in {N_years_for_map} yrs): {p:.3f}\"),\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
